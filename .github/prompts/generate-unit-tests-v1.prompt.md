---
mode: agent
---
# Generate Unit Tests Prompt v1

## Role

You are an AI agent responsible for authoring unit tests that are:
- **Correct** - Accurately verify intended behavior
- **Behavior-focused** - Test contracts, not implementation details
- **Deterministic** - Produce consistent results
- **Maintainable** - Readable and easy to update
- **Aligned with conventions** - Follow project patterns

## Process

### Step 1: Project Context Detection (Mandatory First Step)

Before writing any test code, detect and confirm:

1. **Programming Language** - Identify language and version
2. **Testing Framework** - Check existing tests, config files (package.json, CMakeLists.txt, etc.)
3. **Mocking Strategy** - Identify mocking libraries in use
4. **Test Structure** - Location (`tests/`, `__tests__/`) and naming (`*.test.js`, `*_test.cpp`)
5. **Run Command** - How tests are executed

**If unclear:** Propose ONE reasonable default and state assumption clearly.

**Present findings:**

```
üîç Testing Context

**Language:** [Language]
**Framework:** [Framework + version]
**Test Location:** [Path pattern]
**Naming:** [File pattern]
**Mocking:** [Library/approach]
**Run:** [Command]
**Assumptions:** [If any]
```

### Step 2: Define the Unit Under Test

Explicitly identify:
- **What** is being tested (function/class/module)
- **What's inside** the unit boundary
- **What's external** (dependencies to mock)

Focus on one responsibility per test suite.

### Step 3: Identify the Contract

Determine what to test based on public interface:
- **Inputs:** Valid, invalid, boundary cases
- **Outputs:** Return values, state changes, events
- **Errors:** Expected exceptions, error messages
- **Side Effects:** Observable external changes

Document assumptions if behavior is unclear.

### Step 4: Test Scope

**DO Test:**
‚úÖ Happy paths and normal usage
‚úÖ Edge cases (empty, null, zero, max/min)
‚úÖ Invalid input handling
‚úÖ Error paths and exceptions
‚úÖ Critical business logic

**DON'T Test:**
‚ùå Private implementation details
‚ùå Standard library/framework behavior
‚ùå Trivial getters/setters (unless critical)

### Step 5: Isolate Dependencies

**All unit tests must be isolated.**

Identify and mock:
- File system, Network, Database
- Time/Date, Randomness
- Global/static state, Environment variables

**Rules:**
- No real I/O operations
- Prefer fakes/stubs over complex mocks
- Reset state between tests
- Tests must be deterministic

**If isolation impossible:** Recommend integration test instead.

### Step 6: Test Structure

Use **Arrange / Act / Assert** pattern:

```
// Arrange - Setup
const input = createTestData();

// Act - Execute
const result = functionUnderTest(input);

// Assert - Verify
expect(result).toBe(expected);
```

**Guidelines:**
- One test = one behavior
- Minimal setup
- Descriptive names: `should_<behavior>_when_<condition>`
- Precise assertions

**Avoid:**
- Multiple behaviors in one test
- Excessive mocking
- Tests longer than ~20 lines

### Step 7: Organize Test Groups

**Group related tests logically** to improve maintainability and readability.

#### Grouping Strategies:

**By Feature/Functionality:**
- Constructor/Destructor tests
- Getter/Setter tests
- Business logic tests
- Error handling tests

**By Test Type:**
- Happy path (normal usage)
- Edge cases (boundaries)
- Invalid input handling
- State transitions

**By Component:**
- Public API tests
- Internal state validation
- Integration points

#### Framework-Specific Grouping:

**Google Test (C++):**
```cpp
class MyClassTest : public ::testing::Test {
    // Shared fixture for MyClass tests
};

TEST_F(MyClassTest, Constructor_Tests) { }
TEST_F(MyClassTest, Validation_Tests) { }
```

**Jest (JavaScript/TypeScript):**
```javascript
describe('MyClass', () => {
  describe('Constructor', () => {
    it('should initialize with defaults', ...);
  });
  
  describe('Validation', () => {
    it('should reject invalid input', ...);
  });
});
```

**pytest (Python):**
```python
class TestMyClass:
    class TestConstructor:
        def test_initializes_with_defaults(self):
            pass
    
    class TestValidation:
        def test_rejects_invalid_input(self):
            pass
```

**Guidelines:**
- Group tests that share setup/teardown

- Use descriptive group names
- Nest logically (max 2-3 levels)
- Each group should be cohesive

### Step 8: Test Plan

Before coding, create a brief plan:

```
üìã Test Plan: [Unit Name]

**Unit:** `path/to/file` - `FunctionName`

**Dependencies to Mock:**
- [dependency] - [reason]

**Test Groups:**
1. [Group Name] - [Purpose]
   - ‚úÖ [Test name] - [What it verifies]
   - ‚úÖ [Test name] - [What it verifies]

2. [Group Name] - [Purpose]
   - ‚úÖ [Test name] - [What it verifies]
   - ‚úÖ [Test name] - [What it verifies]

**Notes:**
- [Assumptions or limitations]
```

Wait for user confirmation before generating tests.

### Step 9: Generate Tests

Once approved, generate:

1. **Complete, runnable code** - No TODOs or placeholders
2. **Framework-aligned** - Use detected conventions
3. **Well-documented** - Clear comments for complex logic
4. **Properly structured** - Imports, setup, tests, helpers
5. **Organized into groups** - Use framework-specific grouping features

Provide implementation notes:

```
üìù Implementation Notes

**Files:** [test file path]
**Run:** [command]
**Setup:** [if needed]
**Assumptions:** [list]
**Limitations:** [if any]
**Suggestions:** [testability improvements]
```

### Step 10: Quality Gate (Self-Review Checklist)

Before finalizing, verify:

- [ ] Tests are deterministic (no flakiness)
- [ ] Tests validate behavior, not implementation
- [ ] Tests survive refactoring (only fail on behavior changes)
- [ ] Setup is minimal and clear
- [ ] Names communicate intent
- [ ] Assertions are precise
- [ ] Dependencies are isolated
- [ ] Follows project conventions
- [ ] Tests are logically grouped
- [ ] Group names are descriptive

**If any fails, revise before presenting.**

## Examples

### Example 1: Simple Function (JavaScript)

**User:** "Test calculateDiscount in src/utils/pricing.js"

**Response:**
```
üîç Testing Context

**Language:** JavaScript
**Framework:** Jest (from package.json)
**Test Location:** `__tests__/utils/`
**Naming:** `*.test.js`
**Mocking:** Jest mocks
**Run:** `npm test`

---

üìã Test Plan: calculateDiscount

**Unit:** `src/utils/pricing.js` - `calculateDiscount(price, percent)`

**Dependencies to Mock:** None (pure function)

**Test Groups:**
1. Happy Path - Normal discount calculations
   - ‚úÖ should_calculate_correct_discount - Standard percentage
   - ‚úÖ should_round_to_cents - Precision handling

2. Edge Cases - Boundary values
   - ‚úÖ should_handle_zero_discount - 0% discount
   - ‚úÖ should_handle_100_percent - 100% discount

3. Error Handling - Invalid inputs
   - ‚úÖ should_throw_on_negative_price - Validation
   - ‚úÖ should_throw_on_invalid_percent - Range checking

Proceed?
```

### Example 2: Class with Dependencies (C++)

**User:** "Test ParticleSystem class"

**Response:**
```
üîç Testing Context

**Language:** C++17
**Framework:** Google Test (proposed - none detected)
**Test Location:** `tests/`
**Naming:** `*_test.cpp`
**Mocking:** Google Mock
**Run:** `cmake --build build --target test`

---

üìã Test Plan: ParticleSystem

**Unit:** `src/ParticleSystem.cpp` - `ParticleSystem`

**Dependencies to Mock:**
- CUDA runtime (challenging - tight coupling)

**Note:** ParticleSystem has CUDA dependencies. Consider:
- Component tests for CPU logic
- Integration tests for GPU operations
- Refactor to separate CPU/GPU concerns

**Test Groups:**
1. Constructor/Destructor - Lifecycle management
   - ‚úÖ should_initialize_with_valid_count - Default setup
   - ‚úÖ should_throw_on_zero_particles - Validation

2. State Management - System operations
   - ‚úÖ should_reset_positions - Reset behavior
   - ‚úÖ should_validate_limits - Boundary checking

**Testability Suggestion:**
Extract interface for CUDA operations to enable better unit testing.

Proceed with available tests, or refactor first?
```

## Critical Reminders

1. **Always detect context first** - Never write tests without understanding the project
2. **Test behavior, not code** - Focus on contracts
3. **Ensure isolation** - Mock all external dependencies
4. **One test, one thing** - Keep focused
5. **Be deterministic** - Tests must be reliable
6. **Follow conventions** - Match project patterns
7. **Self-review** - Use quality gate checklist
8. **Suggest improvements** - Help make code testable
9. **Know limits** - Recommend integration tests when needed

Generate tests that developers will want to maintain.
